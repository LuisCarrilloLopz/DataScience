{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar las librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer, RobustScaler, label_binarize\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, PowerTransformer\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seed=12345 #fijamos la semilla de aleatorización para que sea la misma en todo el proceso\n",
    "#Reemplaza con la ruta correcta y nombre de tu archivo\n",
    "file_path = '/Users/luiscarrillo/Library/CloudStorage/OneDrive-Personal/Desktop/GitHub/DataScience/MachineLearning/Datasets/titanic.xlsx' \n",
    "#convertir a data frame el archivo\n",
    "df = pd.read_excel(file_path)\n",
    "print(df.head())\n",
    "#La variable de interés es chd, binaria Si/No\n",
    "#analizamos la frecuencia de cada clase\n",
    "print(f'\\n Instancias: {df.shape[0]}; Variables: {df.shape[1]}')\n",
    "print(f'\\nLa frecuencia de cada clase es: \\n{df.Survived.value_counts()}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fccd7dd0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d354ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#representamos la relación enre la variable de interés y las variables input\n",
    "#df['chd_numeric'] = df['Survived'].apply(lambda x: 1 if x == 'Si' else 0)\n",
    "# Crear el diagrama de dispersión con regresión\n",
    "sns.regplot(x=df['Title'], y=df['Survived'], ci=None,fit_reg=False)\n",
    "plt.xlabel('Title ')\n",
    "plt.ylabel('Survived')\n",
    "plt.title('Diagrama de Dispersión')\n",
    "plt.show()\n",
    "# Crear el diagrama de dispersión con regresión\n",
    "sns.regplot(x=df['Age'], y=df['Survived'], ci=None,fit_reg=False)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Survived')\n",
    "plt.title('Diagrama de Dispersión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b0b337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Si se quiere categorizar la variable de respuesta (útil cuando tiene 1/0)\n",
    "df['Survived_numeric'] = df['Survived']\n",
    "df['Survived'] = df['Survived'].apply(lambda x: 'Yes' if x == 1 else 'No')\n",
    "#en nuestro caso, cambiamos Si por Yes\n",
    "#df['chd'] = df['chd'].apply(lambda x: 'Yes' if x == 'Si' else 'No')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fadf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay valores perdidos?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994e857",
   "metadata": {},
   "source": [
    "Preparamos la base de datos para la aplicación de redes neuronales:\n",
    "\n",
    "    - Estandarizar/normalizar variables continuas\n",
    "    - Convertir a dummies las variables categóricas\n",
    "    - Evitar missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organiza las variables según su rol y naturaleza\n",
    "# determina variable objetivo\n",
    "target = \"Survived\"\n",
    "#hacer una lista con las variables input numericas\n",
    "num_cols = ['Age', 'Fare']\n",
    "#hacer una lista con las variables input categóricas\n",
    "cat_cols = ['Sex', 'Pclass', 'Embarked', 'Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir a dummies las categóricas\n",
    "#solo hay una variable categórica, transformación fácil\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Pclass', 'Embarked', 'Title'] ,drop_first=True)\n",
    "# drop_first en la función get_dummies de pandas se utiliza para controlar si se debe eliminar \n",
    "#la primera columna de las variables dummy que se generan. \n",
    "#Cuando drop_first se establece en True, se elimina la primera columna de cada conjunto de variables dummy, lo que ayuda a evitar la multicolinealidad en modelos lineales\n",
    "#otra opción\n",
    "cat_cols = ColumnTransformer(transformers=[ ('ohe', OneHotEncoder(drop='first'), cat_cols)], \n",
    "                                                  remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea939c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizar variables numericas\n",
    "#Si se quisieran estandarizar, scaler=StandardScaler()\n",
    "scaler = MinMaxScaler() #selecciona el transformador\n",
    "X = df[num_cols] #selecciona las variables numéricas que se quieren transformar y las guarda en un nuevo dataframe\n",
    "X_scale = pd.DataFrame(scaler.fit_transform(X)) #guarda el resultado de la transformación de las variables de X en X_scale\n",
    "X_scale.columns = X.columns #para simplificar los nombres, asigna a las columnas de X_scale los nombres de las variables de X_num\n",
    "df[num_cols] = X_scale\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9c3dd",
   "metadata": {},
   "source": [
    "### Otra forma de normalizar los datos para mejorar el rendimiento de la red neuronal\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7136d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separar las variables predictoras y la variable de respuesta.\n",
    "# El grupo de variables predictoras se define y se fija\n",
    "X = df[['Pclass_2','Fare', 'Sex_male']] #en X las variables ya están normalizadas y con dummies\n",
    "y = df['Survived']\n",
    "#primer approach a red neuronal: definimos la estructura\n",
    "red1 = MLPClassifier(random_state=seed, hidden_layer_sizes=(8),activation='tanh',\n",
    "                     alpha=0.001,solver='adam',max_iter=1000)\n",
    "# Dividir los datos en entrenamiento y test (20% de los datos para test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "# Construir el modelo de red ajustando los pesos a datos de train\n",
    "red1.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a66642",
   "metadata": {},
   "source": [
    "## Si se quiere dividir en tr/v/ts\n",
    "### Paso 1: División en entrenamiento y test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "### Paso 2: División del conjunto temporal en validación y test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd53dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la información sobre las capas y los coeficientes del modelo\n",
    "capas = [X_train.shape[1]] + [capa.shape[0] for capa in red1.coefs_] + [len(np.unique(y_train))]\n",
    "\n",
    "# Crear una figura de red neuronal con plotly\n",
    "# Crear una figura de red neuronal con plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Dibujar nodos y conexiones\n",
    "for i in range(1, len(capas)):\n",
    "    capa_anterior = capas[i - 1]\n",
    "    capa_actual = capas[i]\n",
    "\n",
    "    # Dibujar nodos\n",
    "    for nodo_actual in range(capa_actual):\n",
    "        fig.add_trace(go.Scatter(x=[i] * capa_actual, y=list(range(capa_actual)), mode='markers', marker=dict(size=20, color='blue')))\n",
    "\n",
    "        # Dibujar conexiones con nodos de la capa anterior\n",
    "        for nodo_anterior in range(capa_anterior):\n",
    "            fig.add_trace(go.Scatter(x=[i - 1, i], y=[nodo_anterior, nodo_actual], mode='lines', line=dict(color='black')))\n",
    "\n",
    "# Personalizar el diseño del gráfico\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    xaxis=dict(title='Capas'),\n",
    "    yaxis=dict(title='Nodos'),\n",
    "    title='Estructura de la Red Neuronal',\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c4a137",
   "metadata": {},
   "source": [
    "- Probar con 200 iteraciones, qué pasa?\n",
    "\n",
    "- Modificar la estructura de red: ¿qué cantidad de nodos ocultos es apropiada?\n",
    "En este ejemplo, k=3. Como hay 469 observaciones y hemos usado tres variables input, si se reservan aproximandamente 20 observaciones para cada parámetro,la fórmula nos dice que una cantidad razonable de nodos ocultos es 5-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ES IMPORTANTE QUE LA DISTRIBUCIÓN DE LAS CLASES SEA 'SIMILAR' EN TRAIN Y TEST.\n",
    "print(f'La frecuencia de cada clase en train es: \\n{y_train.value_counts(normalize=True)}')\n",
    "print(f'\\nLa frecuencia de cada clase en test es: \\n{y_test.value_counts(normalize=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Niveles de la variable a predecir\n",
    "print(red1.classes_)\n",
    "# Nombre de las variables predictoras\n",
    "print(red1.feature_names_in_)\n",
    "# Cantidad de iteraciones necesarias para la convergencia, \n",
    "#así se puede volver a entrenar el modelo ajustando este parámetro para tener menos coste computacional\n",
    "print(red1.n_iter_) #no ha hecho falta iterar tanto\n",
    "#ver los coeficientes de cada enlace\n",
    "# Acceder a los coeficientes (pesos) de cada capa\n",
    "print(red1.coefs_)\n",
    "#si se quiere ver qué atributos podemos analizar en el modelo\n",
    "#dir(red1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5674593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#una vez ajustado el modelo en datos de train, lo evaluamos en datos de test\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = red1.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "precision = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo en test: {precision:.4f}\")\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz_confusion)\n",
    "\n",
    "# Mostrar el informe de clasificación\n",
    "informe_clasificacion = classification_report(y_test, y_pred)\n",
    "print(\"Informe de clasificación:\")\n",
    "print(informe_clasificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bda041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#otra forma de mostrar la matriz de confusión\n",
    "#ConfusionMatrixDisplay, que espera etiquetas binarias\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "y_pred_encoded = label_encoder.fit_transform(y_pred)\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#una forma de analizar el overfitting es comparando la medida de bondad en train/test\n",
    "#si hay mucha diferencia, es porque el modelo está sobreajustado\n",
    "#si ambas son muy malas, es porque el modelo está poco ajustado\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_tr = red1.predict(X_train)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "precision_tr = accuracy_score(y_train, y_pred_tr)\n",
    "print(f\"Precisión del modelo en train: {precision_tr:.4f}\")\n",
    "print(f\"Precisión del modelo en test: {precision:.4f}\")\n",
    "#este es un ejemplo de modelo sobreajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cc604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validación cruzada para una evaluación más robusta del modelo\n",
    "#importante cambiar el tipo ed scoring atendiendo al tipo de problema\n",
    "cv_scores = cross_val_score(red1, X, y, cv=5, scoring='accuracy')\n",
    "cv_precision_mean = np.mean(cv_scores)\n",
    "\n",
    "print(f'Precisión promedio mediante validación cruzada: {cv_precision_mean:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Tuneo y evaluación predictiva del modelo para variable dependiente continua\n",
    "# El grupo de variables predictoras se define y se fija\n",
    "X = df[['Pclass_2','Fare', 'Sex_male']] #en X las variables ya están normalizadas y con dummies\n",
    "y = df['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "red = MLPClassifier()\n",
    "#definimos los parámetros que queremos tunear\n",
    "params = {\n",
    "    'max_iter': [600],\n",
    "    'hidden_layer_sizes': [5,7,9],\n",
    "    'activation': ['tanh','relu'],\n",
    "    'alpha': [0.001,0.0001]\n",
    "}\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "# cv = crossvalidation con n folds con todas las combinaciones de parámetros\n",
    "grid_search = GridSearchCV(estimator=red,\n",
    "                           param_grid=params,\n",
    "                           cv=4, scoring = scoring_metrics, refit='accuracy')\n",
    "\n",
    "#ajusta en entrenamiento con todas las combinaciones\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f821c93a0d4cd019",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Obtener resultados del grid search\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "# Mostrar resultados\n",
    "print(\"Resultados de Grid Search:\")\n",
    "print(results[['params', 'mean_test_accuracy', 'mean_test_precision_macro', 'mean_test_recall_macro', 'mean_test_f1_macro']])\n",
    "#print(results) #para ver todos los atributos obtenidos y entender cómo usarlos\n",
    "\n",
    "# Obtener el mejor modelo (en cuanto a optimización del criterio)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(grid_search.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31f1bbf135162366",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60f0656646d6c699",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# se seleccionan los modelos candidatos, y analiza su robustez a lo largo de cross validation.\n",
    "ac_1 = results[['split0_test_accuracy', 'split1_test_accuracy','split2_test_accuracy', 'split3_test_accuracy']].iloc[0]\n",
    "ac_2 = results[['split0_test_accuracy', 'split1_test_accuracy','split2_test_accuracy', 'split3_test_accuracy']].iloc[7]\n",
    "ac_3 = results[['split0_test_accuracy', 'split1_test_accuracy','split2_test_accuracy', 'split3_test_accuracy']].iloc[11]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5732c6d599e9f69e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Crear un boxplot para los cuatro valores de accuracy\n",
    "plt.boxplot([ac_1.values,ac_2.values,ac_3.values], labels = ['Red0','Red7','Red11'])\n",
    "plt.title('Boxplots de Accuracy para los 4 Splits')\n",
    "plt.xlabel('Splits de Cross Validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ae8e6ea65948197",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#analizar y reentrenar redes candidatas AUC\n",
    "red1 = MLPClassifier(**results.iloc[0].params)\n",
    "red7 = MLPClassifier(**results.iloc[7].params)\n",
    "red10 = MLPClassifier(**results.iloc[11].params)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cc3cb1c17adea79",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_auc = pd.get_dummies(y,drop_first=True) #para calcular el AUC, y debe ser numérica\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_auc, test_size=0.2, random_state=seed)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af197c9756bd3c02",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Fit the models\n",
    "red1.fit(X_train, y_train)\n",
    "red7.fit(X_train, y_train)\n",
    "red10.fit(X_train, y_train)\n",
    "\n",
    "# Calculamos las predicciones en test, en términos de probabilidad para poder dibujar el AUC\n",
    "y_pred1 = red1.predict_proba(X_test)[:,1]\n",
    "y_pred7 = red7.predict_proba(X_test)[:,1]\n",
    "y_pred10 = red10.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f\"\\nÁrea bajo la curva ROC (AUC) para la red 1 en test: {roc_auc:.2f}\")\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC red1')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5080bb72980bc381",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e850b52baec84f0a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
