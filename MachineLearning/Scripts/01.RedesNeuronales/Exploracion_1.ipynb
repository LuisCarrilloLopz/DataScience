{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40401e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#instalamos las librerías necesarias\n",
    "import os #chdir() permite cambiar el directorio actual   \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sklearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE, RFECV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer, RobustScaler, label_binarize\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import BaggingClassifier,  GradientBoostingClassifier, StackingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, plot_confusion_matrix, roc_auc_score, roc_curve, auc, precision_score, recall_score\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_predict, cross_val_score, GridSearchCV, KFold, LeaveOneOut, RandomizedSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import get_logger\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61137b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algunas funciones importantes \n",
    "#dibujar la matriz de confusion\n",
    "def plot_confusion_matrix(X, y, gsearch, p, seed):\n",
    "  print('\\n================================================')\n",
    "  print('MATRIZ DE CONFUSION:')\n",
    "  print('================================================')\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = p, random_state=seed)\n",
    "\n",
    "  y_hat_train = gsearch.predict(X_train)\n",
    "  y_hat_test = gsearch.predict(X_test)\n",
    "\n",
    "  print('Confusion matrix train:\\n', 'Train score: ', round(gsearch.score(X_train, y_train),3))\n",
    "  ConfusionMatrixDisplay.from_estimator(estimator=gsearch, X=X_train, y=y_train)\n",
    "  plt.show()\n",
    "\n",
    "  print('\\nConfusion matrix test:\\n','Test score: ', round(gsearch.score(X_test, y_test), 3))\n",
    "  ConfusionMatrixDisplay.from_estimator(estimator=gsearch, X=X_test, y=y_test)  \n",
    "  plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc20ff42",
   "metadata": {},
   "source": [
    "# En la documentación hablar sobre librerías imprescindibles\n",
    "NumPy: imprescindible para computación científica, ofrece estructuras de datos como arreglos multidimensionales (arrays) y funciones para operaciones matemáticas eficientes.\n",
    "\n",
    "Pandas: para el manejo y análisis de datos. Proporciona estructuras de datos como DataFrames y Series, facilitando la manipulación y limpieza de datos tabulares.\n",
    "\n",
    "Matplotlib:  para crear visualizaciones gráficas. Ofrece amplias opciones para crear gráficos, histogramas, gráficos de dispersión, entre otros.\n",
    "\n",
    "Seaborn: basada en Matplotlib, es una biblioteca para visualización de datos estadísticos. Ofrece gráficos más atractivos y una integración más sencilla con DataFrames de Pandas.\n",
    "\n",
    "TensorFlow: biblioteca de deep learning desarrollada por Google. Es una de las bibliotecas más populares para construir y entrenar redes neuronales en tareas de inteligencia artificial.\n",
    "\n",
    "scikit-learn: biblioteca de machine learning con una amplia gama de algoritmos y herramientas para clasificación, regresión, agrupamiento, selección de modelos y más.\n",
    "\n",
    "Keras: biblioteca de deep learning que proporciona una interfaz de alto nivel para construir y entrenar redes neuronales de manera rápida y sencilla. Es una API de alto nivel que se ejecuta sobre frameworks de bajo nivel como TensorFlow, Theano o CNTK. Keras facilita la creación de redes neuronales al abstraer muchos de los detalles complicados y proporcionar una sintaxis intuitiva.\n",
    "\n",
    "SciKeras: Es una capa de abstracción que permite utilizar modelos de Keras dentro de scikit-learn, lo que facilita la integración de técnicas de aprendizaje profundo en flujos de trabajo de aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79df966",
   "metadata": {},
   "source": [
    "# Lectura de datos y exploración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a03f4675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customizaciones\n",
    "sns.set_style( 'darkgrid' )\n",
    "np.set_printoptions( precision = 2 )\n",
    "get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings(\"ignore\", message=\"Setting the random state for TF\")\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aab20a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 10)\n",
      "['sbp', 'tobacco', 'ldl', 'adiposity', 'famhist', 'typea', 'obesity', 'alcohol', 'age', 'chd']\n",
      "Absent     270\n",
      "Present    192\n",
      "Name: famhist, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#----- Lectura archivo y primer analisis\n",
    "data_original = pd.read_csv('./SAheart.csv') \n",
    "data = data_original\n",
    "print(data.shape)\n",
    "\n",
    "# Obtener los nombres de las columnas del DataFrame\n",
    "column_names = data.columns.tolist()\n",
    "print(column_names)\n",
    "\n",
    "data.head() #para mostrar las 5 primeras lineas\n",
    "data.describe() #estadisticos basicos de las variables continuas\n",
    "#exploración datos categóricos\n",
    "#Mostrar recuento de categorías únicas en una columna categórica\n",
    "print(data['famhist'].value_counts())\n",
    "\n",
    "\n",
    "# Gráfico de barras para visualizar la distribución de categorías\n",
    "data['famhist'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribución de categorías')\n",
    "plt.xlabel('Categoría')\n",
    "plt.ylabel('Recuento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4b74c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chd       No  Si\n",
      "famhist         \n",
      "Absent   206  64\n",
      "Present   96  96\n",
      "Valor de Chi-cuadrado: 33.1226039295323\n",
      "Valor de p: 8.652695462627767e-09\n"
     ]
    }
   ],
   "source": [
    "# Tabla cruzada entre dos variables categóricas\n",
    "tabla_cruzada = pd.crosstab(data['famhist'], data['chd'])\n",
    "print(tabla_cruzada)\n",
    "\n",
    "# Realizar una prueba de Chi-cuadrado entre dos variables categóricas\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, p, dof, expected = chi2_contingency(tabla_cruzada)\n",
    "print(\"Valor de Chi-cuadrado:\", chi2)\n",
    "\n",
    "# mayor sea el valor de Chi-cuadrado, mayor será la discrepancia y más probable será que las variables estén asociadas\n",
    "#p es mayor que el nivel de significancia, no se puede rechazar la hipótesis nula, \n",
    "#y no hay suficiente evidencia para afirmar que hay una asociación significativa entre las variables.\n",
    "print(\"Valor de p:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f41e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(462, 10)\n",
      "0\n",
      "(462, 10)\n"
     ]
    }
   ],
   "source": [
    "#busca nulos\n",
    "data.isna().sum()\n",
    "\n",
    "#busca duplicados\n",
    "print(data.duplicated().sum()) #para ver si hay alguna obs duplicada\n",
    "print(data.shape) #tamaño (filasxcolumnas) del archivo\n",
    "data = data.drop_duplicates() #eliminar duplicados (si procede)\n",
    "print(data.duplicated().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67145404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determina variable objetivo\n",
    "target = \"chd\"\n",
    "#hacer una lista con las variables input numericas\n",
    "continuas = ['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age']\n",
    "#hacer una lista con las variables input categoricias\n",
    "categoricas = ['famhist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e892cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normaliza variables numericas usando minimo y maximo\n",
    "scaler = MinMaxScaler()\n",
    "X = data[continuas]\n",
    "X_scale = pd.DataFrame(scaler.fit_transform(X))\n",
    "X_scale.columns = X.columns\n",
    "data[continuas] = X_scale   #data tiene las variables continuas normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7902928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normaliza variables numericas usando media y desv.tipica\n",
    "#para no mezclar las transformaciones y puesto que en este caso usaré el resultado de minMax, lo llamo de otra forma\n",
    "scaler2 = StandardScaler()\n",
    "X_otro = data_original[continuas]\n",
    "X_scale_Norm = pd.DataFrame(scaler2.fit_transform(X_otro))\n",
    "X_scale_Norm.columns = X_otro.columns\n",
    "#hago otra copia del data original\n",
    "data2 = data_original\n",
    "data2[continuas] = X_scale_Norm  #data2 tiene las variables continuas estandarizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a9379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasa variables categoricas a dummy\n",
    "#ColumnTransformer permite hacer transformaciones de diverso tipo a distintos tipos de atributos\n",
    "#concretamente, el transformador OneHotEncoder es para transformar a dummies\n",
    "#a cada transformación se le pone un \"nombre\" o \"etiqueta\", en este caso sólo hacemos la transformación OneHotEncoder,\n",
    "#a la que se le asigna el nombre ohe\n",
    "#remainder indica cómo manejar las columnas no incluidas en las transformaciones: 'passthrough' significa que las columnas que no se han transformado mediante OneHotEncoder se mantendrán sin cambios\n",
    "#drop='first' se utiliza para eliminar la primera columna dummy para evitar la multicolinealidad entre dummies. Se elimina una columna para cada característica categórica, por lo que si tienes n categorías en una característica, se crearán n-1 variables dummy para representar esas categorías. \n",
    "#La columna eliminada se considera la referencia.\n",
    "#aquí se define una forma ed transformar, pero no se aplica\n",
    "cat_trans_cols = ColumnTransformer(transformers=[ ('ohe', OneHotEncoder(drop='first'), categoricas)],\n",
    "                                    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d235003a",
   "metadata": {},
   "source": [
    "# Transformaciones eficaces a atributos\n",
    "ColumnTransformer se utiliza para aplicar transformaciones específicas a columnas particulares en el conjunto de datos, y puedes agregar el paso de creación de variables dummy para las columnas categóricas utilizando la función make_column_transformer. A la vez, se puede aplicar la normalización de las variables continuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a37cc949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sbp   tobacco       ldl  adiposity     typea   obesity   alcohol  \\\n",
      "0    0.504274  0.384615  0.331010   0.457902  0.553846  0.332497  0.660371   \n",
      "1    0.367521  0.000321  0.239024   0.611748  0.646154  0.444479  0.013996   \n",
      "2    0.145299  0.002564  0.174216   0.714406  0.600000  0.452949  0.025885   \n",
      "3    0.589744  0.240385  0.378397   0.875245  0.584615  0.542346  0.164821   \n",
      "4    0.282051  0.435897  0.175610   0.588531  0.723077  0.354141  0.389565   \n",
      "..        ...       ...       ...        ...       ...       ...       ...   \n",
      "457  0.965812  0.012821  0.348432   0.698741  0.784615  0.431305  0.000000   \n",
      "458  0.692308  0.134615  0.239024   0.709371  0.600000  0.436324  0.127183   \n",
      "459  0.059829  0.096154  0.042509   0.237483  0.415385  0.169072  0.180991   \n",
      "460  0.145299  0.173077  0.740767   0.672727  0.784615  0.396801  0.162851   \n",
      "461  0.264957  0.000000  0.267596   0.746014  0.753846  0.000000  0.000000   \n",
      "\n",
      "          age  famhist_Absent  famhist_Present  \n",
      "0    0.755102             0.0              1.0  \n",
      "1    0.979592             1.0              0.0  \n",
      "2    0.632653             0.0              1.0  \n",
      "3    0.877551             0.0              1.0  \n",
      "4    0.693878             0.0              1.0  \n",
      "..        ...             ...              ...  \n",
      "457  0.877551             1.0              0.0  \n",
      "458  0.755102             1.0              0.0  \n",
      "459  0.816327             1.0              0.0  \n",
      "460  0.510204             1.0              0.0  \n",
      "461  0.632653             0.0              1.0  \n",
      "\n",
      "[462 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Definir el ColumnTransformer\n",
    "preprocessor = make_column_transformer(\n",
    "    (MinMaxScaler(), continuas), # Escalar características numéricas\n",
    "    (OneHotEncoder(), categoricas)         # Crear variables dummy para la columna categórica 'gender'\n",
    ")\n",
    "#si no se quieren incluir todas las dummies, (drop='first')\n",
    "#si se crean todas, luego se puede decidir qué categoría se usa\n",
    "# Aplicar el ColumnTransformer para obtener las variables dummy y las características restantes\n",
    "transformed_data = preprocessor.fit_transform(data_original)\n",
    "\n",
    "# Convertir el resultado a un DataFrame si se quiere  visualizarlo\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=preprocessor.get_feature_names_out(input_features=data.columns))\n",
    "\n",
    "# Eliminar el sufijo \"_suffix\" de todas las variables del DataFrame\n",
    "transformed_df.rename(columns={col: col.replace('minmaxscaler__', '') for col in transformed_df.columns}, inplace=True)\n",
    "transformed_df.rename(columns={col: col.replace('onehotencoder__', '') for col in transformed_df.columns}, inplace=True)\n",
    "print(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f949ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#el problema del uso directo de make_column_transformer es que pone a las variables transformadas el sufijo del cambio hecho\n",
    "#lo cual puede hacer incómodo el uso posterior de las variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661daf0a",
   "metadata": {},
   "source": [
    "# Otro uso de los transformadores\n",
    "Es posible definir las transformaciones (cambios a dummies, normalizaciones, etc), sin necesidad de crear un nuevo data en el que se recojan estos cambios. Para ello, se define un pipeline que combina la definición de la transformación con la aplicación de algún modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "306798ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.7096774193548387\n"
     ]
    }
   ],
   "source": [
    "# Definir el ColumnTransformer\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), continuas), # Escalar características numéricas\n",
    "    (OneHotEncoder(), categoricas)         # Crear variables dummy para la columna categórica 'gender'\n",
    ")\n",
    "\n",
    "# Crear un pipeline con el preprocesamiento y el modelo de clasificación\n",
    "model = make_pipeline(preprocessor, LogisticRegression())\n",
    "#como le voy a aplicar el transformador al pipeline, hay que proporcionarle las variables originales\n",
    "explicativas = data_original.drop(target, axis=1)\n",
    "y = data_original[target]\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(explicativas, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión del modelo:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1d598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3616aa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>462.000000</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.319033</td>\n",
       "      <td>0.116527</td>\n",
       "      <td>0.262044</td>\n",
       "      <td>0.522146</td>\n",
       "      <td>0.616983</td>\n",
       "      <td>0.355838</td>\n",
       "      <td>0.115799</td>\n",
       "      <td>0.567674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.175182</td>\n",
       "      <td>0.147212</td>\n",
       "      <td>0.144314</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>0.151039</td>\n",
       "      <td>0.132173</td>\n",
       "      <td>0.166323</td>\n",
       "      <td>0.298142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.160453</td>\n",
       "      <td>0.364615</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.259881</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.326531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.234146</td>\n",
       "      <td>0.541958</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.348338</td>\n",
       "      <td>0.051022</td>\n",
       "      <td>0.612245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.401709</td>\n",
       "      <td>0.176282</td>\n",
       "      <td>0.335192</td>\n",
       "      <td>0.684965</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.432795</td>\n",
       "      <td>0.162324</td>\n",
       "      <td>0.816327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sbp     tobacco         ldl   adiposity       typea     obesity  \\\n",
       "count  462.000000  462.000000  462.000000  462.000000  462.000000  462.000000   \n",
       "mean     0.319033    0.116527    0.262044    0.522146    0.616983    0.355838   \n",
       "std      0.175182    0.147212    0.144314    0.217642    0.151039    0.132173   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.196581    0.001683    0.160453    0.364615    0.523077    0.259881   \n",
       "50%      0.282051    0.064103    0.234146    0.541958    0.615385    0.348338   \n",
       "75%      0.401709    0.176282    0.335192    0.684965    0.723077    0.432795   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          alcohol         age  \n",
       "count  462.000000  462.000000  \n",
       "mean     0.115799    0.567674  \n",
       "std      0.166323    0.298142  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.003465    0.326531  \n",
       "50%      0.051022    0.612245  \n",
       "75%      0.162324    0.816327  \n",
       "max      1.000000    1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define X y Y (se utiliza después)\n",
    "X = data[continuas] #ahora X incluye las variables continuas, habiendo sido normalizadas minMax\n",
    "y = data[target]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114726e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_80c4e_row0_col0, #T_80c4e_row1_col1, #T_80c4e_row2_col2, #T_80c4e_row3_col3, #T_80c4e_row4_col4, #T_80c4e_row5_col5, #T_80c4e_row6_col6, #T_80c4e_row7_col7 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row0_col1 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row0_col2, #T_80c4e_row1_col2, #T_80c4e_row6_col0, #T_80c4e_row6_col7 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row0_col3 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row0_col4 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row0_col5 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row0_col6 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row0_col7 {\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row1_col0 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row1_col3 {\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row1_col4 {\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row1_col5, #T_80c4e_row4_col2 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row1_col6 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row1_col7 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row2_col0 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row2_col1 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row2_col3 {\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row2_col4 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row2_col5 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row2_col6, #T_80c4e_row4_col0, #T_80c4e_row4_col1, #T_80c4e_row4_col3, #T_80c4e_row4_col7, #T_80c4e_row6_col2, #T_80c4e_row6_col5, #T_80c4e_row7_col4 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row2_col7 {\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row3_col0 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row3_col1 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row3_col2, #T_80c4e_row7_col1 {\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row3_col4 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row3_col5 {\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row3_col6, #T_80c4e_row7_col6 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row3_col7 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row4_col5 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row4_col6 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row5_col0 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row5_col1, #T_80c4e_row6_col3 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row5_col2 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row5_col3 {\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row5_col4 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row5_col6 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row5_col7 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row6_col1 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row6_col4 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_80c4e_row7_col0 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row7_col2 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row7_col3 {\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_80c4e_row7_col5 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_80c4e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_80c4e_level0_col0\" class=\"col_heading level0 col0\" >sbp</th>\n",
       "      <th id=\"T_80c4e_level0_col1\" class=\"col_heading level0 col1\" >tobacco</th>\n",
       "      <th id=\"T_80c4e_level0_col2\" class=\"col_heading level0 col2\" >ldl</th>\n",
       "      <th id=\"T_80c4e_level0_col3\" class=\"col_heading level0 col3\" >adiposity</th>\n",
       "      <th id=\"T_80c4e_level0_col4\" class=\"col_heading level0 col4\" >typea</th>\n",
       "      <th id=\"T_80c4e_level0_col5\" class=\"col_heading level0 col5\" >obesity</th>\n",
       "      <th id=\"T_80c4e_level0_col6\" class=\"col_heading level0 col6\" >alcohol</th>\n",
       "      <th id=\"T_80c4e_level0_col7\" class=\"col_heading level0 col7\" >age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_80c4e_level0_row0\" class=\"row_heading level0 row0\" >sbp</th>\n",
       "      <td id=\"T_80c4e_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_80c4e_row0_col1\" class=\"data row0 col1\" >0.212247</td>\n",
       "      <td id=\"T_80c4e_row0_col2\" class=\"data row0 col2\" >0.158296</td>\n",
       "      <td id=\"T_80c4e_row0_col3\" class=\"data row0 col3\" >0.356500</td>\n",
       "      <td id=\"T_80c4e_row0_col4\" class=\"data row0 col4\" >-0.057454</td>\n",
       "      <td id=\"T_80c4e_row0_col5\" class=\"data row0 col5\" >0.238067</td>\n",
       "      <td id=\"T_80c4e_row0_col6\" class=\"data row0 col6\" >0.140096</td>\n",
       "      <td id=\"T_80c4e_row0_col7\" class=\"data row0 col7\" >0.388771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_80c4e_level0_row1\" class=\"row_heading level0 row1\" >tobacco</th>\n",
       "      <td id=\"T_80c4e_row1_col0\" class=\"data row1 col0\" >0.212247</td>\n",
       "      <td id=\"T_80c4e_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_80c4e_row1_col2\" class=\"data row1 col2\" >0.158905</td>\n",
       "      <td id=\"T_80c4e_row1_col3\" class=\"data row1 col3\" >0.286640</td>\n",
       "      <td id=\"T_80c4e_row1_col4\" class=\"data row1 col4\" >-0.014608</td>\n",
       "      <td id=\"T_80c4e_row1_col5\" class=\"data row1 col5\" >0.124529</td>\n",
       "      <td id=\"T_80c4e_row1_col6\" class=\"data row1 col6\" >0.200813</td>\n",
       "      <td id=\"T_80c4e_row1_col7\" class=\"data row1 col7\" >0.450330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_80c4e_level0_row2\" class=\"row_heading level0 row2\" >ldl</th>\n",
       "      <td id=\"T_80c4e_row2_col0\" class=\"data row2 col0\" >0.158296</td>\n",
       "      <td id=\"T_80c4e_row2_col1\" class=\"data row2 col1\" >0.158905</td>\n",
       "      <td id=\"T_80c4e_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_80c4e_row2_col3\" class=\"data row2 col3\" >0.440432</td>\n",
       "      <td id=\"T_80c4e_row2_col4\" class=\"data row2 col4\" >0.044048</td>\n",
       "      <td id=\"T_80c4e_row2_col5\" class=\"data row2 col5\" >0.330506</td>\n",
       "      <td id=\"T_80c4e_row2_col6\" class=\"data row2 col6\" >-0.033403</td>\n",
       "      <td id=\"T_80c4e_row2_col7\" class=\"data row2 col7\" >0.311799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_80c4e_level0_row3\" class=\"row_heading level0 row3\" >adiposity</th>\n",
       "      <td id=\"T_80c4e_row3_col0\" class=\"data row3 col0\" >0.356500</td>\n",
       "      <td id=\"T_80c4e_row3_col1\" class=\"data row3 col1\" >0.286640</td>\n",
       "      <td id=\"T_80c4e_row3_col2\" class=\"data row3 col2\" >0.440432</td>\n",
       "      <td id=\"T_80c4e_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_80c4e_row3_col4\" class=\"data row3 col4\" >-0.043144</td>\n",
       "      <td id=\"T_80c4e_row3_col5\" class=\"data row3 col5\" >0.716556</td>\n",
       "      <td id=\"T_80c4e_row3_col6\" class=\"data row3 col6\" >0.100330</td>\n",
       "      <td id=\"T_80c4e_row3_col7\" class=\"data row3 col7\" >0.625954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_80c4e_level0_row4\" class=\"row_heading level0 row4\" >typea</th>\n",
       "      <td id=\"T_80c4e_row4_col0\" class=\"data row4 col0\" >-0.057454</td>\n",
       "      <td id=\"T_80c4e_row4_col1\" class=\"data row4 col1\" >-0.014608</td>\n",
       "      <td id=\"T_80c4e_row4_col2\" class=\"data row4 col2\" >0.044048</td>\n",
       "      <td id=\"T_80c4e_row4_col3\" class=\"data row4 col3\" >-0.043144</td>\n",
       "      <td id=\"T_80c4e_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_80c4e_row4_col5\" class=\"data row4 col5\" >0.074006</td>\n",
       "      <td id=\"T_80c4e_row4_col6\" class=\"data row4 col6\" >0.039498</td>\n",
       "      <td id=\"T_80c4e_row4_col7\" class=\"data row4 col7\" >-0.102606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_80c4e_level0_row5\" class=\"row_heading level0 row5\" >obesity</th>\n",
       "      <td id=\"T_80c4e_row5_col0\" class=\"data row5 col0\" >0.238067</td>\n",
       "      <td id=\"T_80c4e_row5_col1\" class=\"data row5 col1\" >0.124529</td>\n",
       "      <td id=\"T_80c4e_row5_col2\" class=\"data row5 col2\" >0.330506</td>\n",
       "      <td id=\"T_80c4e_row5_col3\" class=\"data row5 col3\" >0.716556</td>\n",
       "      <td id=\"T_80c4e_row5_col4\" class=\"data row5 col4\" >0.074006</td>\n",
       "      <td id=\"T_80c4e_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_80c4e_row5_col6\" class=\"data row5 col6\" >0.051620</td>\n",
       "      <td id=\"T_80c4e_row5_col7\" class=\"data row5 col7\" >0.291777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_80c4e_level0_row6\" class=\"row_heading level0 row6\" >alcohol</th>\n",
       "      <td id=\"T_80c4e_row6_col0\" class=\"data row6 col0\" >0.140096</td>\n",
       "      <td id=\"T_80c4e_row6_col1\" class=\"data row6 col1\" >0.200813</td>\n",
       "      <td id=\"T_80c4e_row6_col2\" class=\"data row6 col2\" >-0.033403</td>\n",
       "      <td id=\"T_80c4e_row6_col3\" class=\"data row6 col3\" >0.100330</td>\n",
       "      <td id=\"T_80c4e_row6_col4\" class=\"data row6 col4\" >0.039498</td>\n",
       "      <td id=\"T_80c4e_row6_col5\" class=\"data row6 col5\" >0.051620</td>\n",
       "      <td id=\"T_80c4e_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_80c4e_row6_col7\" class=\"data row6 col7\" >0.101125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_80c4e_level0_row7\" class=\"row_heading level0 row7\" >age</th>\n",
       "      <td id=\"T_80c4e_row7_col0\" class=\"data row7 col0\" >0.388771</td>\n",
       "      <td id=\"T_80c4e_row7_col1\" class=\"data row7 col1\" >0.450330</td>\n",
       "      <td id=\"T_80c4e_row7_col2\" class=\"data row7 col2\" >0.311799</td>\n",
       "      <td id=\"T_80c4e_row7_col3\" class=\"data row7 col3\" >0.625954</td>\n",
       "      <td id=\"T_80c4e_row7_col4\" class=\"data row7 col4\" >-0.102606</td>\n",
       "      <td id=\"T_80c4e_row7_col5\" class=\"data row7 col5\" >0.291777</td>\n",
       "      <td id=\"T_80c4e_row7_col6\" class=\"data row7 col6\" >0.101125</td>\n",
       "      <td id=\"T_80c4e_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f9450473a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correlación entre variables numéricas\n",
    "X.corr().style.background_gradient(cmap='coolwarm')\n",
    "#otra opción\n",
    "#correlacion = X.corr().style.background_gradient(cmap='coolwarm')\n",
    "#display(correlacion) #solo disponible en Jupyter\n",
    "#se puede cambiar la forma de colores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72f5ae",
   "metadata": {},
   "source": [
    "# Selección de variables: explicar en la documentación SelectKBest (hay que especificar k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35c01dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#OJO: para hacer seleccion k-beast es importante que las variables posibles, X, no sean negativas (estamos hablando todo de continuas)\n",
    "#por lo tanto, mejor normalizar (max,min) que estandarizar (mu,sigma)\n",
    "#k indica la cantidad de atributos que serán seleccionados como los mejores para el modelo\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=3)\n",
    "selector.fit(X,y)\n",
    "\n",
    "df_chi2 = pd.DataFrame(zip(selector.pvalues_, X.columns), columns=[\"pvalor\", \"feature\"]).sort_values(\"pvalor\")\n",
    "\n",
    "plt.barh(y=df_chi2[\"feature\"], width=df_chi2[\"pvalor\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e205a07",
   "metadata": {},
   "source": [
    "# Explicar en la documentacion ExtraTreesClassifier:\n",
    "Algoritmo de clasificación basado en árboles de decisión de la biblioteca scikit-learn. Construye árboles extremadamente aleatorios, al igual Random Forest, ExtraTrees utiliza ensamblaje de árboles, pero con una diferencia clave en su proceso de entrenamiento.\n",
    "\n",
    "Ensamblaje de árboles: construye múltiples árboles de decisión para formar un clasificador más robusto y preciso.\n",
    "\n",
    "Bootstrapping: para cada árbol en el ensamblaje, aplica bootstrapping para generar muestras aleatorias con reemplazo a partir del conjunto de entrenamiento original. Esto implica que cada árbol verá un subconjunto diferente de los datos.\n",
    "\n",
    "Aleatoriedad en la construcción del árbol: nn lugar de buscar el mejor punto de división en cada nodo como en los árboles de decisión tradicionales, ExtraTreesClassifier selecciona puntos de división al azar. Esto introduce más aleatoriedad y evita la elección de características óptimas en cada nodo.\n",
    "\n",
    "Votación para la predicción: cuando todos los árboles están construidos, las predicciones finales del ExtraTreesClassifier se obtienen mediante votación. Cada árbol vota por la clase más probable y la clase con más votos, teniendo en cuenta todos los árboles obtenidos, se convierte en la predicción final.\n",
    "\n",
    "El ExtraTreesClassifier es útil para tareas de clasificación, especialmente cuando se trabaja con conjuntos de datos de alta dimensionalidad o con características redundantes. La aleatoriedad en la construcción de los árboles ayuda a reducir el sobreajuste y mejorar la generalización del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97df4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ojo que aquí se aplica directamente sin hacer división en train/test, porque no nos interesa tanto obtener un modelo\n",
    "#predictivo como tener una idea sobre las variables mas interesantes\n",
    "#como sólo hay una categórica, se analizan únicamente ahora las continuas\n",
    "model = ExtraTreesClassifier() #se selecciona el tipo de modelo que se aplicará\n",
    "model.fit(X, y) #se ajusta el modelo escogido usando como input las variables en X y como output/target, y\n",
    "model.feature_importances_ #se calcula, para este modelo, cómo de importante han sido las variables\n",
    "\n",
    "pd.DataFrame(zip(model.feature_importances_, X.columns), \n",
    "             columns=['importance', 'feature']).\\\n",
    "             sort_values('importance', ascending=False)\n",
    "\n",
    "#para definir el gráfico de barras, se define qué hay en cada eje y qué se representa\n",
    "plt.barh(y=X.columns, width=model.feature_importances_) \n",
    "#para mostrar el gráfico de barras\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12878a75",
   "metadata": {},
   "source": [
    "# Qué es StratifiedKFold\n",
    " Es una técnica de validación cruzada que se utiliza para evaluar el rendimiento de un modelo de clasificación. Es una variante de la validación cruzada k-fold que garantiza que las proporciones de clases se mantengan en cada partición del conjunto de datos.\n",
    "Validación cruzada k-fold: divide el conjunto de datos en k pliegues (folds) o particiones del mismo tamaño. Luego, entrena el modelo k veces, utilizando cada uno de los pliegues como conjunto de prueba y los restantes como conjunto de entrenamiento (donde dice pliegue habitualmente se habla de grupos)\n",
    "\n",
    "StratifiedKFold: En la validación cruzada k-fold tradicional, las particiones se generan de manera aleatoria, lo que podría resultar en distribuciones desiguales de clases en los pliegues. StratifiedKFold, en cambio, asegura que las proporciones de clases se mantengan en cada partición.\n",
    "\n",
    "La ventaja de usar StratifiedKFold es que proporciona una evaluación más confiable del rendimiento del modelo, especialmente cuando se trata de conjuntos de datos desequilibrados, donde una clase tiene muchas más muestras que otras.\n",
    "\n",
    "## Parámetros StratifiedKFold\n",
    "\n",
    "n_splits: número de grupos (folds) en los que se divide el conjunto de datos. Especifica la cantidad de iteraciones de entrenamiento y prueba que se realizarán durante la validación cruzada. Por defecto, n_splits=5.\n",
    "\n",
    "shuffle: valor booleano que indica si los datos deben ser mezclados antes de dividirlos en grupos. Si se establece en True, los datos se reordenarán aleatoriamente antes de realizar la validación cruzada. Por defecto, shuffle = False.\n",
    "\n",
    "random_state: controla la semilla utilizada para la generación de números aleatorios cuando shuffle=True. Proporcionar un valor específico para random_state garantiza que los resultados sean reproducibles.\n",
    "\n",
    "stratify: arreglo o serie de etiquetas (clases) que indica la distribución de las clases en el conjunto de datos. StratifiedKFold asegurará que las proporciones de clases se mantengan en cada partición. Si no se proporciona, stratify se establecerá automáticamente en y (etiquetas de destino) por defecto.\n",
    "\n",
    "indices: este parámetro no es parte de la clase StratifiedKFold en sí, pero es utilizado para acceder a los índices de entrenamiento y prueba de cada fold durante la validación cruzada. Puedes utilizar este parámetro en un bucle for para obtener los índices de entrenamiento y prueba en cada iteración.\n",
    "\n",
    "## RFECV (Recursive Feature Elimination with Cross-Validation) \n",
    "\n",
    "Técnica de selección de características de scikit-learn. Es una variante del algoritmo de eliminación recursiva de características (Recursive Feature Elimination, RFE) que incorpora validación cruzada (Cross-Validation) para mejorar la selección de características y evitar el sobreajuste.\n",
    "\n",
    "La selección de características puede ayudar a reducir la dimensionalidad del conjunto de datos y mejorar la precisión del modelo al eliminar características irrelevantes o redundantes.\n",
    "\n",
    "1. Eliminación recursiva de características: empieza con todas las características en el modelo y realiza la CV con un estimador específico. Luego, identifica y elimina la característica menos importante según algún criterio (por defecto, utiliza el coeficiente más bajo de importancia de las características).\n",
    "\n",
    "2. Validación cruzada (CV): después de eliminar la característica menos importante, el modelo se vuelve a entrenar y se evalúa utilizando validación cruzada. Este paso ayuda a estimar el rendimiento del modelo con la característica eliminada.\n",
    "\n",
    "3. Repeticiones: Repite los pasos 1 y 2 hasta que se alcance un número específico de características seleccionadas o hasta que el rendimiento del modelo no mejore significativamente.\n",
    "\n",
    "El uso de validación cruzada en RFECV permite una evaluación más precisa del rendimiento del modelo durante la selección de características, ya que evita el sobreajuste y proporciona una estimación más realista del rendimiento del modelo en datos no vistos.\n",
    "\n",
    "## ¿Con qué criterio se evalúa la bondad del modelo? Scoring\n",
    "1. Para problemas de clasificación:\n",
    "- accuracy: precisión, que es la proporción de muestras clasificadas correctamente.\n",
    "- precision: precisión del clasificador, que es la proporción de verdaderos positivos sobre el total de predicciones positivas (TP / (TP + FP)).\n",
    "- recall: sensibilidad, que es la proporción de verdaderos positivos sobre el total de muestras positivas (TP / (TP + FN)).\n",
    "- f1: puntuación F1, que es la media armónica de precisión y recall.\n",
    "- roc_auc: ñarea bajo la curva ROC, que mide la capacidad de discriminación del clasificador.\n",
    "\n",
    "2. Para problemas de regresión:\n",
    "- neg_mean_squared_error: error cuadrático medio negativo, que mide el promedio de los errores al cuadrado entre las predicciones y los valores reales (negativo porque scikit-learn espera que las métricas de puntuación sean maximizadas).\n",
    "- r2: coeficiente de determinación R^2, que mide la proporción de la varianza de la variable dependiente que es predecible a partir de las variables independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de631b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: The `grid_scores_` attribute is deprecated in version 1.0 in favor of `cv_results_` and will be removed in version 1.2.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#para que todo el proceso sea reproducible, fijamos la semilla de aleatorización, seed, desde el principio\n",
    "#se define el tipo de stratifiedKFold que se aplica, en este caso con 10 grupos y remuestreo\n",
    "#en este ejemplo, como estimador se propone un Random Forest con n_estimator=50 árboles ensamblados\n",
    "#la idea aquí es simplemente utilizar este clasificador como método para evaluar la importancia de las variables, \n",
    "#no tanto tratar de ajustar un buen modelo predictivo\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "estimator = RandomForestClassifier(n_estimators=50, random_state=seed)\n",
    "\n",
    "#una vez definida la estructura de StratifiedCV y el modelo que se usará como base, se aplica la selección RFECV\n",
    "#STEP determina la cantidad de características que se eliminarán en cada iteración\n",
    "#step=0.5: en cada iteración, se eliminará la mitad de las características menos importantes.\n",
    "#step=2: en cada iteración, se eliminarán dos características menos importantes.\n",
    "selector = RFECV(estimator, step=1, cv=kfold, scoring=\"accuracy\", n_jobs=-1)\n",
    "selector = selector.fit(X, y)\n",
    "selector.n_features_\n",
    "\n",
    "skf = pd.DataFrame(zip(selector.ranking_, selector.grid_scores_, X.columns), \n",
    "                   columns=['importance', 'score', 'feature']).\\\n",
    "                   sort_values('importance', ascending=False).head()\n",
    "skf[\"score\"] = skf[\"score\"].apply(lambda x: x.mean())\n",
    "skf\n",
    "\n",
    "plt.barh(y=skf[\"feature\"], width=skf[\"score\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b04172",
   "metadata": {},
   "source": [
    "## Una vez aplicados distintos criterios de selección, se escogen las variables candidatas\n",
    "Por la tabla cruzada entre la única categórica que hay, famhist, y la target, chd, como se rechaza H0, podemos afirmar\n",
    "que famhist sí tiene relación con chd, por lo que habrá que tenerla en cuenta. Además, servirá para ilustrar la forma\n",
    "de utilizar variables categóricas, especialmente en redes neuronales\n",
    "\n",
    "Las variables seleccionadas como input candidatas serán\n",
    "- famhist (habrá que ver cómo usar sus categorías)\n",
    "- age, tobacco, obesity, typea, adiposity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883396b",
   "metadata": {},
   "source": [
    "# Técnicas de Validación\n",
    "La mejor forma de evaluar un modelo será hacer predicciones para nuevos datos para los que ya se conocen las respuestas\n",
    "Aplicaremos técnicas de remuestreo que permitan hacer estimaciones precisas de cómo de bien se ajusta un modelo. En este caso vamos a ver técnicas de división en Train-Test y técnicas de validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1700542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#División Train-Test, usando train_test_split de sklearn.model_prediction\n",
    "#Train-Test es la técnica de remuestreo más sencilla y rápida, y es ideal para datasets grande, pero podría no ajustar bie\n",
    "#datasets muy sesgados\n",
    "#hay que especificar el tamaño de la partición para evaluar, en este caso hacemos un Tr/Ts (80,20)\n",
    "#la estructura básica es\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deb72794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos los grupos de variables input con los que se harán pruebas\n",
    "#RECORDATORIO: data ahora contiene las variables continuas normalizadas\n",
    "#armazena las variables selecionadas para cada scenario\n",
    "select_cols = ['age', 'tobacco', 'obesity', 'typea', 'adiposity', 'famhist']\n",
    "X_todas = data.drop(target, axis=1) #elimina de data la variable definida como target\n",
    "X_num = data[continuas] #selecciona únicamente las variables numéricas\n",
    "X_select = data[select_cols]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1972d026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6989247311827957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "plot_confusion_matrix only supports classifiers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28828\\593108782.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mconf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Si'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'No'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#definimos cómo está etiquetada la variable objetivo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#función definida al inicio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(estimator, X, y_true, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"plot_confusion_matrix only supports classifiers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: plot_confusion_matrix only supports classifiers"
     ]
    }
   ],
   "source": [
    "\n",
    "#para tener algo con lo que compararnos, partimos de una regresión logística\n",
    "#para que el proceso sea reproducible, es importante fijar la semilla de aleatorización, random_state\n",
    "regression_model = LogisticRegression(random_state=seed)\n",
    "#forma sencilla de una posible aplicación rápida y sin parámetros de regresión, utilizando todas las variables\n",
    "X_num_tr, X_num_ts, Y_train, Y_test = train_test_split(X_num, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "regression_model.fit(X_num_tr, Y_train)\n",
    "#una vez entrenado el modelo, evaluamos su bondad\n",
    "\n",
    "# sabiendo que el conjunto de prueba es X_num_ts, Y_test\n",
    "Y_pred = regression_model.predict(X_num_ts) #se calcula la predicción que se obtendría al aplicar el modelo\n",
    "\n",
    "#calculamos medidas de bondad, comparando la parte de test reservada para la variable objetivo y las predicciones obtenidas\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(accuracy)\n",
    "#al calcular la precisión, en pos_label hay que especificar la categoría positiva de la variable objetivo, dependiendo de las etiquetas\n",
    "precision = precision_score(Y_test, Y_pred, pos_label='Si')\n",
    "recall = recall_score(Y_test, Y_pred, pos_label='Si')\n",
    "f1 = f1_score(Y_test, Y_pred, pos_label='Si')\n",
    "\n",
    "print(f'Precisión: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')\n",
    "\n",
    "#para modelos de regresión lineal\n",
    "#y_pred = model.predict(X_test)\n",
    "#mse = mean_squared_error(y_test, y_pred)\n",
    "#r2 = r2_score(y_test, y_pred)\n",
    "#print(f'MSE: {mse}')\n",
    "#print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50112a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parametrización de la regresión: método de optimización utilizado, iterciones consideradas\n",
    "logistic_regression_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Ajustar (entrenar) el modelo utilizando los datos de entrenamiento\n",
    "logistic_regression_model.fit(X_num_tr, Y_train)\n",
    "\n",
    "# Realizar predicciones en los datos de prueba\n",
    "y_pred = logistic_regression_model.predict(X_num_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa17b40",
   "metadata": {},
   "source": [
    "# Solver  (regresión)\n",
    "\n",
    "- newton-cg: método de Newton conjugado para la optimización. Es adecuado para conjuntos de datos pequeños o medianos.\n",
    "\n",
    "- lbfgs:  algoritmo BFGS, adecuado para conjuntos de datos pequeños o medianos.\n",
    "\n",
    "- liblinear:  el algoritmo de descenso de coordenadas. Es más rápido para conjuntos de datos grandes y es el recomendado para conjuntos de datos con una gran cantidad de muestras.\n",
    "\n",
    "- sag:  método de promedio de gradiente estocástico (Stochastic Average Gradient), adecuado para conjuntos de datos grandes y también es eficiente en términos de memoria.\n",
    "\n",
    "- saga: variante del algoritmo SAG que también admite penalizaciones L1. Es eficiente para problemas grandes y permite la regularización L1.\n",
    "\n",
    "Cada algoritmo de optimización tiene sus propias ventajas y desventajas, y la elección del solver dependerá del tamaño del conjunto de datos, la cantidad de muestras, la convergencia, y otros factores. En general, 'liblinear' es una buena opción para conjuntos de datos grandes, mientras que 'newton-cg', 'lbfgs', 'sag', o 'saga' son más adecuados para conjuntos de datos pequeños o medianos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e58721",
   "metadata": {},
   "source": [
    "# Estructura para el entrenamiento de redes neuronales \n",
    "1. Preparar los datos: cargar y preprocesar los datos de entrenamiento y prueba. Esto incluye dividir los datos en características (X) y etiquetas/clases (y), así como normalizar o estandarizar las características para facilitar el entrenamiento, solucionar problemas de datos faltantes y convertir a dummies las variables categóricas.\n",
    "\n",
    "2. Diseñar la arquitectura de la red neuronal: definir la arquitectura de la red neuronal, incluyendo el número de capas ocultas, el número de neuronas en cada capa, la función de activación, entre otros.\n",
    "\n",
    "3. Crear el modelo: Crear el modelo de red neuronal utilizando alguna biblioteca de deep learning en Python, como TensorFlow o Keras.\n",
    "\n",
    "4. Compilar el modelo: Compilar el modelo definiendo la función de pérdida, el algoritmo de optimización y las métricas de evaluación.\n",
    "\n",
    "5. Entrenar el modelo: Ajustar el modelo utilizando los datos de entrenamiento mediante el método fit().\n",
    "\n",
    "6. Evaluar el rendimiento: Evaluar el rendimiento del modelo utilizando los datos de prueba y diferentes métricas de evaluación.\n",
    "\n",
    "## Tuneo de redes\n",
    "\n",
    "- Parámetro losss\n",
    "1. Problemas de clasificación binaria (dos clases): binary_crossentropy es la función de pérdida más común para problemas de clasificación binaria. Se utiliza cuando solo hay dos clases en el problema y la salida del modelo es un valor entre 0 y 1 (por ejemplo, en una capa de salida con activación sigmoide).\n",
    "\n",
    "2. Problemas de clasificación multiclase (más de dos clases): \n",
    "    a. categorical_crossentropy se utiliza cuando hay más de dos clases en el problema y la salida del modelo es un vector de probabilidades para cada clase. Suele estar asociada con la activación 'softmax' en la capa de salida.\n",
    "    b. sparse_categorical_crossentropy similar a 'categorical_crossentropy', pero se utiliza cuando las etiquetas son enteros en lugar de codificación one-hot (es decir, etiquetas enteras en lugar de vectores de probabilidades).\n",
    "    \n",
    "3. Problemas de regresión: mean_squared_error es la función de pérdida más común para problemas de regresión. Se utiliza cuando el objetivo es predecir un valor numérico y la salida del modelo es una sola neurona sin función de activación.\n",
    "\n",
    "- Parámetro Dense indica que es una red completamente conectada, es decir, que en cada capa, todos los nodos están conectados con todos los nodos (y ninguno más) de las capas anterior y siguiente el número que se indica a continuación especifica cuántas neuronas hay en esa capa, en el caso de la capa input, debe coincidir con el número de variables que se quieren usar, en este caso, continuas tiene 8 variables es posible modificar la función de activación, usando una en cada capa o la misma siempre hay que especificar cuántos nodos tiene cada capa\n",
    "\n",
    "- Parámetro batch_size indica la cantidad de muestras de entrenamiento que se utilizarán para calcular el gradiente y actualizar los pesos del modelo en una sola iteración del algoritmo de optimización. .Cuando entrenamos un modelo de aprendizaje automático, generalmente utilizamos un conjunto de datos de entrenamiento que contiene muchas muestras. En lugar de procesar todas las muestras a la vez, el entrenamiento se realiza de forma iterativa en mini lotes o \"batches\". El tamaño de estos lotes está determinado por el parámetro batch_size esta idea permite paralelizar el proceso, mejora la convergencia y el uso de memoria batch_size suele ser un número entre 32 y 256\n",
    "\n",
    "- Parámetro epoch: un epoch se completa cuando el modelo ha visto y procesado todos los lotes del conjunto de entrenamiento una vez. Importante: equilibrio al elegir el número de epoch. Un número insuficiente puede resultar en un modelo subentrenado que no ha capturado completamente los patrones en los datos; un número excesivo puede provocar sobreentrenamiento, donde el modelo memoriza los datos de entrenamiento y no generaliza bien a nuevos datos. La cantidad de epochs se ajusta a través de la validación cruzada y el seguimiento del rendimiento del modelo en un conjunto de datos de validación. Cuando el rendimiento del modelo en el conjunto de validación deja de mejorar o comienza a deteriorarse, se considera que el modelo ha convergido y el entrenamiento se detiene.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54902f00",
   "metadata": {},
   "source": [
    "# Estructura básica de evaluación con validación cruzada explicar en la documentación\n",
    "## IMPORTANTE: cross_val_score es una función de sklearn, no se puede aplicar directamente a una función de keras, como la definición secuencial del modelo de redes\n",
    "Se utiliza la función cross_val_score, con parámetros:\n",
    "- model: modelo que se quiere evaluar\n",
    "- scoring: medida de bondad\n",
    "- cv: tipo de CV que se quiere aplicar, por defecto CV con 5 grupos\n",
    "\n",
    "El resultado de cross_val_score es una lista con la el resultado de la medida de ajuste escogida calculada en cada uno de los grupos. Esto permite hacer la agregación de resultados que sea más conveniente y analizar la estabilidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b2b16cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3629, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"pandas\\_libs\\index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'famhist'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 433, in _get_column_indices\n",
      "    col_idx = all_columns.get_loc(col)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3631, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'famhist'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 672, in fit_transform\n",
      "    self._validate_column_callables(X)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 352, in _validate_column_callables\n",
      "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 441, in _get_column_indices\n",
      "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
      "ValueError: A given column is not a column of the dataframe\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "#Para aplicar CV NO hay que partir de la división en train/test, sino de todos los datos, en este caso, X_num, \n",
    "#para utilizar como input todas las variables numéricas e y.\n",
    "#definimos un modelo de red neuronal\n",
    "#PROPUESTA: tilizar el adaptador KerasClassifier o KerasRegressor proporcionado por scikit-learn para envolver el \n",
    "#modelo de Keras y hacerlo compatible con las funciones de scikit-learn que requieren estimadores\n",
    "\n",
    "# Define la función que crea el modelo de Keras\n",
    "def create_model():\n",
    "    model.add(Dense(8, input_dim=X_num.shape[1], activation='tanh')) #capa input\n",
    "    model.add(Dense(5, activation='relu')) #capa oculta, la ajustamos con 3 neuronas artificiales\n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Crea el modelo de KerasClassifier\n",
    "red = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32)\n",
    "\n",
    "# Utiliza el modelo de KerasClassifier con funciones de scikit-learn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Por ejemplo, realiza validación cruzada\n",
    "scoring='accuracy'\n",
    "scores = cross_val_score(model, X_num, y, cv=5,scoring=scoring)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df207195",
   "metadata": {},
   "source": [
    "# Tuneo y evaluación de redes neuronales con sklearn\n",
    "1. Carga y preprocesamiento de datos: Carga los datos de y realiza el preprocesamiento necesario: escalamiento de variables numéricas, codificación de variables categóricas, manejo de valores faltantes, entre otros.\n",
    "\n",
    "2. División de datos: Divide los datos en conjuntos de entrenamiento y prueba para poder evaluar el rendimiento del modelo en datos no vistos.\n",
    "\n",
    "3. Definición del modelo: Crea la arquitectura de la red neuronal definiendo el número de capas, el número de unidades en cada capa, las funciones de activación, etc.\n",
    "\n",
    "4. Tuneo de hiperparámetros: Utiliza técnicas como la búsqueda de hiperparámetros (por ejemplo, GridSearchCV o RandomizedSearchCV de scikit-learn) para encontrar los mejores valores de hiperparámetros para tu red neuronal.\n",
    "\n",
    "5. Entrenamiento del modelo: Entrena el modelo con los datos de entrenamiento utilizando el método fit(), ajustando los hiperparámetros obtenidos en el paso anterior.\n",
    "\n",
    "6. Evaluación del modelo: Evalúa el rendimiento del modelo en el conjunto de prueba utilizando métricas relevantes (por ejemplo, precisión, recall, F1-score, etc.).\n",
    "\n",
    "En sklearn NO es necesario hacer la compilación del modelo. Para especificar el algoritmo de optimización se puede usar solver "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f1455",
   "metadata": {},
   "source": [
    "# Parámetros de MLPClassifier  \n",
    "Perceptrón Multicapa (MLP) para tareas de clasificación en aprendizaje automático. El Perceptrón Multicapa es un tipo de red neuronal artificial con múltiples capas, que puede aprender relaciones no lineales y complejas en los datos.\n",
    "\n",
    "El MLPClassifier utiliza el algoritmo de retropropagación (backpropagation) para ajustar los pesos de las conexiones entre las neuronas durante el proceso de entrenamiento. Este algoritmo busca minimizar la función de pérdida para mejorar la precisión de las predicciones del modelo. Algunos de los parámetros más importantes del MLPClassifier son:\n",
    "\n",
    "- hidden_layer_sizes: tupla que especifica el número de neuronas en cada capa oculta. Por ejemplo, (10, 5) indica que el modelo tiene dos capas ocultas, la primera con 10 neuronas artificales y la segunda con 5 neuronas artificiales. En general, en problemas de clasificación bastará con usar una sola capa oculta.\n",
    "\n",
    "- activation: función de activación utilizada en las capas ocultas. Las opciones comunes son 'relu' para funciones no lineales y 'logistic' para funciones sigmoidales, o tanh.\n",
    "\n",
    "- solver: algoritmo de optimización utilizado para ajustar los pesos del modelo. Algunas opciones populares son 'adam', 'sgd' (descenso de gradiente estocástico) y 'lbfgs' (algoritmo de cuasi-Newton).\n",
    "\n",
    "- alpha: parámetro de regularización L2 para controlar la penalización de los pesos grandes y evitar el sobreajuste.\n",
    "\n",
    "- learning_rate: esquema de tasa de aprendizaje que determina cómo se ajustan los pesos durante el entrenamiento. Puede ser 'constant', 'invscaling' o 'adaptive'.\n",
    "\n",
    "- max_iter: El número máximo de itera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bf30e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(462, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'max_iter': 500, 'solver': 'adam'}\n",
      "Precisión en el conjunto de prueba: 0.6774193548387096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_original = pd.read_csv('./SAheart.csv') \n",
    "data = data_original\n",
    "\n",
    "\n",
    "#busca nulos\n",
    "data.isna().sum()\n",
    "\n",
    "# determina variable objetivo\n",
    "target = \"chd\"\n",
    "#hacer una lista con las variables input numericas\n",
    "continuas = ['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age']\n",
    "#hacer una lista con las variables input categoricias\n",
    "categoricas = ['famhist']\n",
    "\n",
    "\n",
    "#busca duplicados\n",
    "print(data.duplicated().sum()) #para ver si hay alguna obs duplicada\n",
    "print(data.shape) #tamaño (filasxcolumnas) del archivo\n",
    "data = data.drop_duplicates() #eliminar duplicados (si procede)\n",
    "\n",
    "\n",
    "#normaliza variables numericas usando media y desv.tipica\n",
    "scaler = StandardScaler()\n",
    "X = data[continuas]\n",
    "X_scale = pd.DataFrame(scaler.fit_transform(X))\n",
    "X_scale.columns = X.columns\n",
    "data[continuas] = X_scale\n",
    "\n",
    "#crear dummies\n",
    "#aquí se define una forma ed transformar, pero no se aplic\n",
    "cat_trans_cols = ColumnTransformer(transformers=[ ('ohe', OneHotEncoder(drop='first'), categoricas)],\n",
    "                                    remainder='passthrough')\n",
    "\n",
    "\n",
    "#definir la variable objetivo\n",
    "y = data[target]\n",
    "# 2. División de datos en conjuntos de entrenamiento y prueba,\n",
    "#usando las variables ya preprocesadas (ojo que no se están usando\n",
    "#las categóricas)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Definición del modelo, para que sea repoducible usar siempre la misma semilla\n",
    "red = MLPClassifier(random_state=seed)\n",
    "\n",
    "# 4. Tuneo de hiperparámetros utilizando GridSearchCV\n",
    "parameters = {'hidden_layer_sizes': [(5,), (10,), (15, ), (20, )],\n",
    "              'alpha': [0.0001, 0.001, 0.01],\n",
    "              'activation': ['relu', 'tanh'], 'solver': ['adam'], 'max_iter': [300, 500, 600]}\n",
    "grid_search = GridSearchCV(red, parameters, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros encontrados:\", best_params)\n",
    "\n",
    "# 5. Entrenamiento del modelo con los mejores hiperparámetros\n",
    "best_model = MLPClassifier(**best_params, random_state=seed)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluación del modelo en el conjunto de prueba\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Precisión en el conjunto de prueba:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851071f",
   "metadata": {},
   "source": [
    "# Análisis de resultados\n",
    "usando el atributo .best_params sólo obtenemos la parametrización propuesta que mejores resultados arroja\n",
    "si se quieren ver los resultados de todos los modelos para poder analizarlos se puede utilizar el atributo cv_results_ diccionario que contiene diversas métricas y estadísticas para cada ajuste realizado durante la búsqueda de hiperparámetros\n",
    "\n",
    "- mean_fit_time: Tiempo promedio de ajuste para cada combinación de hiperparámetros.\n",
    "- std_fit_time: Desviación estándar del tiempo de ajuste para cada combinación de hiperparámetros.\n",
    "- mean_score_time: Tiempo promedio de evaluación en el conjunto de prueba para cada combinación de hiperparámetros.\n",
    "- std_score_time: Desviación estándar del tiempo de evaluación en el conjunto de prueba para cada combinación de hiperparámetros.\n",
    "- params: Lista de diccionarios que contienen los valores de los hiperparámetros para cada combinación.\n",
    "- mean_test_score: Promedio de las puntuaciones de rendimiento en el conjunto de prueba para cada combinación de hiperparámetros.\n",
    "- std_test_score: Desviación estándar de las puntuaciones de rendimiento en el conjunto de prueba para cada combinación de hiperparámetros.\n",
    "- rank_test_score: El rango del rendimiento en el conjunto de prueba para cada combinación de hiperparámetros (1 es el mejor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e97c5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               params  mean_test_score  \\\n",
      "0   {'activation': 'relu', 'alpha': 0.0001, 'hidde...         0.669377   \n",
      "1   {'activation': 'relu', 'alpha': 0.0001, 'hidde...         0.666667   \n",
      "2   {'activation': 'relu', 'alpha': 0.0001, 'hidde...         0.663957   \n",
      "3   {'activation': 'relu', 'alpha': 0.0001, 'hidde...         0.674797   \n",
      "4   {'activation': 'relu', 'alpha': 0.0001, 'hidde...         0.682927   \n",
      "..                                                ...              ...   \n",
      "67  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...         0.704607   \n",
      "68  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...         0.701897   \n",
      "69  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...         0.707317   \n",
      "70  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...         0.715447   \n",
      "71  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...         0.707317   \n",
      "\n",
      "    std_test_score  rank_test_score  \n",
      "0         0.026828               64  \n",
      "1         0.033191               67  \n",
      "2         0.025132               71  \n",
      "3         0.043529               62  \n",
      "4         0.040378               55  \n",
      "..             ...              ...  \n",
      "67        0.033411               25  \n",
      "68        0.040560               31  \n",
      "69        0.035126               19  \n",
      "70        0.033191                3  \n",
      "71        0.039829               19  \n",
      "\n",
      "[72 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ver todos los resultados de los modelos ajustados. Esta forma de verlo no es muy intuitiva\n",
    "print(grid_search.cv_results_)\n",
    "\n",
    "#Para mejorar la visualización, convertir cv_results_ en un DataFrame de pandas\n",
    "cv_results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Mostrar los resultados en forma de lista\n",
    "result_list = cv_results_df[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f9f972",
   "metadata": {},
   "source": [
    "# Evaluación del modelo con CV usando sklearn\n",
    "Una vez escogida la mejor parametrización, el modelo se vuelve a entrenar para evaluar su ajuste aplicando validación cruzada\n",
    "Mejores hiperparámetros encontrados: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'max_iter': 500, 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f68f1d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión promedio con validación cruzada: 0.7099345488546049\n",
      "Precisión en cada grupo de validación cruzada: [0.75 0.68 0.63 0.73 0.76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Crear un modelo MLPClassifier con los hiperparámetros seleccionados\n",
    "model = MLPClassifier(hidden_layer_sizes=(15,), activation='tanh', solver='adam', random_state=seed)\n",
    "\n",
    "# Realizar validación cruzada con 5 grupos y obtener la precisión promedio\n",
    "scores = cross_val_score(model, X_scale, y, cv=5, scoring='accuracy')\n",
    "mean_accuracy = scores.mean()\n",
    "\n",
    "print(\"Precisión promedio con validación cruzada:\", mean_accuracy)\n",
    "print(\"Precisión en cada grupo de validación cruzada:\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40203d63",
   "metadata": {},
   "source": [
    "# Evaluación del modelo con repeated CV usando sklearn\n",
    "Una vez escogida la mejor parametrización, el modelo se vuelve a entrenar para evaluar su ajuste aplicando validación cruzada Mejores hiperparámetros encontrados: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'max_iter': 500, 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "50943286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test score: 0.6916, Std test score: 0.0310, Rank test score: 2, Parameters: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: 0.6916, Std test score: 0.0310, Rank test score: 2, Parameters: {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: 0.6918, Std test score: 0.0316, Rank test score: 1, Parameters: {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'max_iter': 600, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#la parametrización también se le puede dar a la función MLPClassifier\n",
    "model = MLPClassifier(random_state=seed)\n",
    "param_grid = {'hidden_layer_sizes': [(15,)],\n",
    "              'alpha': [0.001],\n",
    "              'activation': ['tanh'], 'solver': ['adam'],\n",
    "              'max_iter': [600]}\n",
    "# Realizar validación cruzada repetida (10 repeticiones, 5 folds)\n",
    "repcv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=seed)\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros con validación cruzada repetida\n",
    "grid_search = GridSearchCV(model, param_grid, cv=repcv)\n",
    "grid_search.fit(X_scale, y)\n",
    "\n",
    "# Obtener los resultados y métricas\n",
    "mean_test_scores = grid_search.cv_results_['mean_test_score']\n",
    "std_test_scores = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "rank_test_scores = grid_search.cv_results_['rank_test_score']\n",
    "\n",
    "# Mostrar los resultados en forma de lista\n",
    "for mean_score, std_score, param, rank_score in zip(mean_test_scores, std_test_scores, params, rank_test_scores):\n",
    "    print(f\"Mean test score: {mean_score:.4f}, Std test score: {std_score:.4f}, Rank test score: {rank_score}, Parameters: {param}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d0d00",
   "metadata": {},
   "source": [
    "si en vez de aplicar repeatCV a una parametrización concreta se quiere hacer el tuneo sobre este tipo de remuestreo, basta con implementar todas las parametrizaciones en param_grid\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "640176d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "180 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 427, in _fit\n",
      "    self._fit_stochastic(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 635, in _fit_stochastic\n",
      "    batch_loss, coef_grads, intercept_grads = self._backprop(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 307, in _backprop\n",
      "    inplace_derivative = DERIVATIVES[self.activation]\n",
      "KeyError: 'softmax'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test score: 0.7165, Std test score: 0.0439, Rank test score: 8, Parameters: {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: 0.7187, Std test score: 0.0421, Rank test score: 5, Parameters: {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (20,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: 0.7208, Std test score: 0.0441, Rank test score: 1, Parameters: {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (25,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: 0.7165, Std test score: 0.0439, Rank test score: 8, Parameters: {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: 0.7187, Std test score: 0.0421, Rank test score: 5, Parameters: {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (20,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: 0.7198, Std test score: 0.0430, Rank test score: 2, Parameters: {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (25,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: 0.7181, Std test score: 0.0420, Rank test score: 7, Parameters: {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: 0.7197, Std test score: 0.0417, Rank test score: 3, Parameters: {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (20,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: 0.7187, Std test score: 0.0433, Rank test score: 4, Parameters: {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (25,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: nan, Std test score: nan, Rank test score: 11, Parameters: {'activation': 'softmax', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: nan, Std test score: nan, Rank test score: 12, Parameters: {'activation': 'softmax', 'alpha': 0.001, 'hidden_layer_sizes': (20,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: nan, Std test score: nan, Rank test score: 13, Parameters: {'activation': 'softmax', 'alpha': 0.001, 'hidden_layer_sizes': (25,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: nan, Std test score: nan, Rank test score: 14, Parameters: {'activation': 'softmax', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: nan, Std test score: nan, Rank test score: 15, Parameters: {'activation': 'softmax', 'alpha': 0.01, 'hidden_layer_sizes': (20,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: nan, Std test score: nan, Rank test score: 16, Parameters: {'activation': 'softmax', 'alpha': 0.01, 'hidden_layer_sizes': (25,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: nan, Std test score: nan, Rank test score: 17, Parameters: {'activation': 'softmax', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: nan, Std test score: nan, Rank test score: 10, Parameters: {'activation': 'softmax', 'alpha': 0.1, 'hidden_layer_sizes': (20,), 'max_iter': 600, 'solver': 'adam'}\n",
      "Mean test score: nan, Std test score: nan, Rank test score: 18, Parameters: {'activation': 'softmax', 'alpha': 0.1, 'hidden_layer_sizes': (25,), 'max_iter': 600, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "red2 = MLPClassifier(random_state=seed)\n",
    "param_grid = {'hidden_layer_sizes': [(15,), (20,), (25,)],\n",
    "              'alpha': [0.001, 0.01, 0.1],\n",
    "              'activation': ['tanh', 'softmax'], 'solver': ['adam'],\n",
    "              'max_iter': [600]}\n",
    "# Realizar validación cruzada repetida (10 repeticiones, 5 folds)\n",
    "repcv = RepeatedKFold(n_splits=5, n_repeats=4, random_state=seed)\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros con validación cruzada repetida\n",
    "#seleccionamos las variables input de la red del conjunto transformado\n",
    "explicativas = transformed_df[['tobacco', 'age', 'famhist_Absent']]\n",
    "grid_search = GridSearchCV(red2, param_grid, cv=repcv)\n",
    "grid_search.fit(explicativas, y)\n",
    "\n",
    "# Obtener los resultados y métricas\n",
    "mean_test_scores = grid_search.cv_results_['mean_test_score']\n",
    "std_test_scores = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "rank_test_scores = grid_search.cv_results_['rank_test_score']\n",
    "\n",
    "# Mostrar los resultados en forma de lista\n",
    "for mean_score, std_score, param, rank_score in zip(mean_test_scores, std_test_scores, params, rank_test_scores):\n",
    "    print(f\"Mean test score: {mean_score:.4f}, Std test score: {std_score:.4f}, Rank test score: {rank_score}, Parameters: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfc5d05",
   "metadata": {},
   "source": [
    "Entender y adaptar la función test_3_variable_selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
